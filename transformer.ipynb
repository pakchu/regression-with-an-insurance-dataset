{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "model_path = './transformer_model/'\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "device = torch.device(\"mps\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐글 노트북이면 True, 아니면 False\n",
    "if 'KAGGLE_URL_BASE' in os.environ:\n",
    "    train_data = pd.read_csv('/kaggle/input/playground-series-s4e12/train.csv', index_col=0)\n",
    "    test_data = pd.read_csv('/kaggle/input/playground-series-s4e12/test.csv', index_col=0)\n",
    "else:\n",
    "    train_data = pd.read_csv('./kaggle/input/playground-series-s4e12/train.csv', index_col=0)\n",
    "    test_data = pd.read_csv('./kaggle/input/playground-series-s4e12/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = train_data.columns.str.lower().str.replace(' ', '_')\n",
    "test_data.columns = test_data.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# 타겟 변수 및 피처 분리\n",
    "target_column = 'premium_amount'\n",
    "train_columns = train_data.columns.drop(target_column)\n",
    "data = pd.concat([train_data, test_data]).drop(columns=target_column)\n",
    "y = train_data[target_column].dropna().values\n",
    "del train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_start_date 피처 전처리\n",
    "data['policy_start_date'] = pd.to_datetime(data['policy_start_date'])\n",
    "data['policy_start_date'] = (data['policy_start_date'] - pd.to_datetime('1970-01-01')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchStandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, data: torch.Tensor):\n",
    "        \"\"\"\n",
    "        데이터의 평균(mean)과 표준 편차(std)를 계산하여 저장.\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor): 학습할 데이터 텐서.\n",
    "        \"\"\"\n",
    "        if not isinstance(data, torch.Tensor):\n",
    "            raise ValueError(\"Input data must be a PyTorch tensor.\")\n",
    "        \n",
    "        self.mean_ = data.mean(dim=0, keepdim=True)\n",
    "        self.std_ = data.std(dim=0, unbiased=False, keepdim=True)\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        데이터를 표준화 (mean=0, std=1)합니다.\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor): 표준화할 데이터 텐서.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: 표준화된 데이터.\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler has not been fitted yet.\")\n",
    "        return (data - self.mean_) / (self.std_ + 1e-8)  # 안정성을 위해 작은 값 추가\n",
    "\n",
    "    def inverse_transform(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        표준화된 데이터를 원래 스케일로 복원합니다.\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor): 복원할 데이터 텐서.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: 원래 스케일로 변환된 데이터.\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Scaler has not been fitted yet.\")\n",
    "        return data * self.std_ + self.mean_\n",
    "\n",
    "    def fit_transform(self, data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        데이터를 학습(fit)하고, 표준화(transform)한 결과를 반환합니다.\n",
    "\n",
    "        Args:\n",
    "            data (torch.Tensor): 학습하고 표준화할 데이터 텐서.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: 표준화된 데이터.\n",
    "        \"\"\"\n",
    "        self.fit(data)\n",
    "        return self.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error, r2_score, mean_squared_error\n",
    "# --- 2. 결측치 처리 ---\n",
    "# 범주형 변수의 결측치를 'unknown'으로 대체\n",
    "categorical_columns = data.select_dtypes(include='object').columns\n",
    "for col in categorical_columns:\n",
    "    data[col].fillna('unknown', inplace=True)\n",
    "\n",
    "# 수치형 변수의 결측치를 최대값 + 10%로 대체\n",
    "float_columns = data.select_dtypes(include=['float64']).columns\n",
    "for col in float_columns:\n",
    "    data[col].fillna(data[col].max() * 1.1, inplace=True)\n",
    "    \n",
    "int_columns = data.select_dtypes(include=['int64']).columns\n",
    "for col in int_columns:\n",
    "    data[col].fillna(data[col].max()+int(data[col].std()), inplace=True)\n",
    "numerical_columns = float_columns.append(int_columns)\n",
    "\n",
    "# --- 3. 범주형 변수 인코딩 및 수치형 스케일링 ---\n",
    "# 범주형 변수 인코딩\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# 수치형 변수 스케일링\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaler.fit(np.log1p(y).reshape(-1,1))\n",
    "y_scaler_torch = TorchStandardScaler()\n",
    "y_scaler_torch.fit(torch.tensor(torch.log1p(torch.tensor(y, dtype=torch.float32).to(device)).squeeze(-1)))\n",
    "y = y_scaler.transform(np.log1p(y).reshape(-1,1)).reshape(-1)\n",
    "\n",
    "data[target_column] = np.pad(y, (0, data.shape[0]-len(y)), 'constant', constant_values=np.nan)\n",
    "X = data[:len(y)].drop(columns=target_column).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_y(y):\n",
    "    return np.expm1(y_scaler.inverse_transform(y.reshape(-1,1)).reshape(-1))\n",
    "\n",
    "def inverse_y_torch(y):\n",
    "    return torch.expm1(y_scaler_torch.inverse_transform(y)).squeeze(-1)\n",
    "\n",
    "def rmlse(preds, dtrain: np.ndarray):\n",
    "    dtrain = inverse_y(dtrain)\n",
    "    preds = inverse_y(preds)\n",
    "    \n",
    "    dtrain = np.log1p(dtrain)\n",
    "    preds = np.log1p(preds)\n",
    "    return 'RMLSE', np.sqrt(mean_squared_error(dtrain, preds)), False\n",
    "\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    \n",
    "    y_pred = inverse_y(y_pred)\n",
    "    y_val = inverse_y(y_val)\n",
    "    \n",
    "    rmsle = mean_squared_log_error(y_val, y_pred) ** (1/2)\n",
    "    return r2, mse, rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>number_of_dependents</th>\n",
       "      <th>education_level</th>\n",
       "      <th>occupation</th>\n",
       "      <th>health_score</th>\n",
       "      <th>location</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>previous_claims</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>insurance_duration</th>\n",
       "      <th>policy_start_date</th>\n",
       "      <th>customer_feedback</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>exercise_frequency</th>\n",
       "      <th>property_type</th>\n",
       "      <th>premium_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.624171</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.685909</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.810261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.359399</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.408224</td>\n",
       "      <td>1.286535</td>\n",
       "      <td>-1.459636</td>\n",
       "      <td>-0.007139</td>\n",
       "      <td>1.300820</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.248538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186740</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.149665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.823814</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.647950</td>\n",
       "      <td>0.420678</td>\n",
       "      <td>0.347957</td>\n",
       "      <td>-1.163606</td>\n",
       "      <td>0.928832</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.646643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.336685</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.300306</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.264546</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.647950</td>\n",
       "      <td>0.767021</td>\n",
       "      <td>1.694669</td>\n",
       "      <td>-0.778117</td>\n",
       "      <td>1.139753</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.229752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.480428</td>\n",
       "      <td>1</td>\n",
       "      <td>2.581937</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.150531</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.129828</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.647950</td>\n",
       "      <td>-1.657378</td>\n",
       "      <td>-1.487704</td>\n",
       "      <td>-1.549096</td>\n",
       "      <td>1.630624</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.480428</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048009</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.810261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.506253</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.887676</td>\n",
       "      <td>-0.272007</td>\n",
       "      <td>-0.190953</td>\n",
       "      <td>-0.392628</td>\n",
       "      <td>-0.141113</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.929390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999995</th>\n",
       "      <td>0.603847</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026464</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.810261</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.894582</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.485609</td>\n",
       "      <td>-0.272007</td>\n",
       "      <td>-1.813296</td>\n",
       "      <td>-1.163606</td>\n",
       "      <td>-0.419145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999996</th>\n",
       "      <td>2.070026</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886280</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.469990</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.314324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.408224</td>\n",
       "      <td>-1.657378</td>\n",
       "      <td>1.694669</td>\n",
       "      <td>-1.163606</td>\n",
       "      <td>0.783105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999997</th>\n",
       "      <td>-1.121070</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.062890</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.469990</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.414036</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.485609</td>\n",
       "      <td>0.074335</td>\n",
       "      <td>1.694669</td>\n",
       "      <td>0.378351</td>\n",
       "      <td>-1.661661</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999998</th>\n",
       "      <td>-0.546098</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197014</td>\n",
       "      <td>2</td>\n",
       "      <td>0.509198</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.799532</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.408224</td>\n",
       "      <td>1.286535</td>\n",
       "      <td>-0.926340</td>\n",
       "      <td>0.763840</td>\n",
       "      <td>0.163764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999999</th>\n",
       "      <td>-1.192942</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.319124</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509198</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.207754</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.485609</td>\n",
       "      <td>0.940192</td>\n",
       "      <td>1.694669</td>\n",
       "      <td>1.149329</td>\n",
       "      <td>-0.518853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  gender  annual_income  marital_status  \\\n",
       "id                                                         \n",
       "0       -1.624171       0      -0.685909               1   \n",
       "1       -0.186740       0      -0.149665               0   \n",
       "2       -1.336685       1      -0.300306               0   \n",
       "3       -1.480428       1       2.581937               1   \n",
       "4       -1.480428       1       0.048009               2   \n",
       "...           ...     ...            ...             ...   \n",
       "1999995  0.603847       0       0.026464               1   \n",
       "1999996  2.070026       0       0.886280               2   \n",
       "1999997 -1.121070       0      -0.062890               2   \n",
       "1999998 -0.546098       0       0.197014               2   \n",
       "1999999 -1.192942       1      -0.319124               0   \n",
       "\n",
       "         number_of_dependents  education_level  occupation  health_score  \\\n",
       "id                                                                         \n",
       "0                   -0.810261                0           1     -0.359399   \n",
       "1                    0.509198                2           3     -0.823814   \n",
       "2                    0.509198                1           1      1.264546   \n",
       "3                   -0.150531                0           3     -1.129828   \n",
       "4                   -0.810261                0           1     -0.506253   \n",
       "...                       ...              ...         ...           ...   \n",
       "1999995             -0.810261                0           3     -0.894582   \n",
       "1999996             -1.469990                2           3     -1.314324   \n",
       "1999997             -1.469990                2           0     -1.414036   \n",
       "1999998              0.509198                2           3     -0.799532   \n",
       "1999999              0.509198                1           3     -0.207754   \n",
       "\n",
       "         location  policy_type  previous_claims  vehicle_age  credit_score  \\\n",
       "id                                                                           \n",
       "0               2            2        -0.408224     1.286535     -1.459636   \n",
       "1               0            1        -0.647950     0.420678      0.347957   \n",
       "2               1            2        -0.647950     0.767021      1.694669   \n",
       "3               0            0        -0.647950    -1.657378     -1.487704   \n",
       "4               0            2        -0.887676    -0.272007     -0.190953   \n",
       "...           ...          ...              ...          ...           ...   \n",
       "1999995         0            2         1.485609    -0.272007     -1.813296   \n",
       "1999996         0            0        -0.408224    -1.657378      1.694669   \n",
       "1999997         2            1         1.485609     0.074335      1.694669   \n",
       "1999998         2            2        -0.408224     1.286535     -0.926340   \n",
       "1999999         1            1         1.485609     0.940192      1.694669   \n",
       "\n",
       "         insurance_duration  policy_start_date  customer_feedback  \\\n",
       "id                                                                  \n",
       "0                 -0.007139           1.300820                  2   \n",
       "1                 -1.163606           0.928832                  0   \n",
       "2                 -0.778117           1.139753                  1   \n",
       "3                 -1.549096           1.630624                  2   \n",
       "4                 -0.392628          -0.141113                  2   \n",
       "...                     ...                ...                ...   \n",
       "1999995           -1.163606          -0.419145                  0   \n",
       "1999996           -1.163606           0.783105                  1   \n",
       "1999997            0.378351          -1.661661                  2   \n",
       "1999998            0.763840           0.163764                  0   \n",
       "1999999            1.149329          -0.518853                  1   \n",
       "\n",
       "         smoking_status  exercise_frequency  property_type  premium_amount  \n",
       "id                                                                          \n",
       "0                     0                   3              2        1.248538  \n",
       "1                     1                   1              2        0.646643  \n",
       "2                     1                   3              2       -0.229752  \n",
       "3                     1                   0              0        0.043158  \n",
       "4                     1                   3              2        0.929390  \n",
       "...                 ...                 ...            ...             ...  \n",
       "1999995               1                   0              1             NaN  \n",
       "1999996               0                   0              0             NaN  \n",
       "1999997               0                   1              0             NaN  \n",
       "1999998               0                   3              1             NaN  \n",
       "1999999               0                   2              2             NaN  \n",
       "\n",
       "[2000000 rows x 20 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 1156\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.000023\n",
      "(0.08951739665142144, 0.912290839924178, 1.0466646556626518)\n",
      "[LightGBM] [Info] Total Bins 1157\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.000404\n",
      "(0.08967290867938316, 0.9152120162325399, 1.0483390385633506)\n",
      "[LightGBM] [Info] Total Bins 1158\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "(0.08747255386017194, 0.9082837691209921, 1.0443634843965353)\n",
      "[LightGBM] [Info] Total Bins 1158\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.000230\n",
      "(0.08822920995613248, 0.917103596715474, 1.0494218445421726)\n",
      "[LightGBM] [Info] Total Bins 1158\n",
      "[LightGBM] [Info] Number of data points in the train set: 960000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.000758\n",
      "(0.08748397038450106, 0.9047018488962898, 1.0423021671089572)\n"
     ]
    }
   ],
   "source": [
    "# --- LGBoost 모델 결과 Feature 로 넣어주기 ---\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "FOLDS=5\n",
    "SPLIT = True\n",
    "\n",
    "# lgb cleanout\n",
    "for col in data.columns:\n",
    "    if 'lgb' in col:\n",
    "        del data[col]\n",
    "kf = KFold(n_splits=FOLDS, \n",
    "           shuffle=False,\n",
    ")\n",
    "_X = X.copy()\n",
    "test_idx = data[target_column].isnull()\n",
    "lgb_fold_predictions = []\n",
    "for train_idx, val_idx in kf.split(_X):\n",
    "    lgb_predictions = np.zeros(len(data))  # 예측값 저장\n",
    "    X_train, X_val = _X.iloc[train_idx], _X.iloc[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    lgbr = LGBMRegressor(\n",
    "        num_leaves=31,\n",
    "        min_child_samples=20,\n",
    "        min_child_weight=0.001,\n",
    "        \n",
    "        n_estimators=500,\n",
    "        max_depth=20,\n",
    "        learning_rate=0.1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        # verbosity=1,\n",
    "        force_row_wise=True,\n",
    "        device=\"gpu\",              # GPU 활성화\n",
    "        gpu_use_dp=True            # 32-bit 정밀도 사용\n",
    "    )\n",
    "    lgbr.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=rmlse,) # use custom rmlse loss function\n",
    "    print(evaluate_model(lgbr, X_val, y_val))\n",
    "    if not SPLIT:\n",
    "        lgb_predictions[val_idx] = lgbr.predict(X_val)\n",
    "        lgb_predictions[test_idx] = lgbr.predict(data.loc[test_idx][train_columns])\n",
    "    else:\n",
    "        lgb_predictions[~np.isin(np.arange(0, len(data)), train_idx)] = lgbr.predict(data[train_columns].loc[~data.index.isin(train_idx)])\n",
    "    \n",
    "    lgb_fold_predictions.append(lgb_predictions)\n",
    "if not SPLIT:\n",
    "    lgb_predictions = np.sum(lgb_fold_predictions, axis=0)\n",
    "    lgb_predictions[:len(y)] = lgb_predictions[:len(y)] / (FOLDS-1)\n",
    "    lgb_predictions[len(y):] = lgb_predictions[len(y):] / FOLDS\n",
    "    data['lgb_pred'] = lgb_predictions\n",
    "else:\n",
    "    lgb_predictions = np.vstack(lgb_fold_predictions).T\n",
    "    data[[f'lgb_pred_{i}' for i in range(lgb_predictions.shape[1])]] = lgb_predictions\n",
    "X = data[:len(y)].drop(columns=target_column).copy()\n",
    "del _X, lgb_predictions, lgb_fold_predictions, lgbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without LGB\n",
    "# lgb cleanout\n",
    "for col in data.columns:\n",
    "    if 'lgb' in col:\n",
    "        del data[col]\n",
    "kf = KFold(n_splits=FOLDS, \n",
    "           shuffle=False,\n",
    ")\n",
    "X = data[:len(y)].drop(columns=target_column).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199995</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199996</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199997</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199998</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199999</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200000 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[1200000 rows x 0 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[:, X.columns.str.contains('lgb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 4. 데이터셋 및 DataLoader 정의 ---\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "val_dataset = TabularDataset(X_val, y_val)\n",
    "test_dataset = torch.tensor(data[data[target_column].isnull()].drop(columns=[target_column]).values, dtype=torch.float32)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Target Loss 정의 ---\n",
    "class RMLSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMLSELoss, self).__init__()\n",
    "    \n",
    "    def forward(self, preds, targets):\n",
    "        # Inverse transform\n",
    "        targets = inverse_y_torch(targets)\n",
    "        preds = inverse_y_torch(preds)\n",
    "\n",
    "        # Log transformation\n",
    "        targets = torch.log1p(targets)\n",
    "        preds = torch.log1p(preds)\n",
    "\n",
    "        # RMLSE 계산\n",
    "        loss = torch.sqrt(torch.mean((preds - targets) ** 2))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 트랜스포머 모델 정의 ---\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, num_layers, hidden_dim, output_dim, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout 추가\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)  # Layer Normalization 추가\n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력 임베딩 및 드롭아웃 적용\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Transformer 인코더와 Layer Normalization 적용\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.layer_norm(x)  # Normalization 추가\n",
    "\n",
    "        # 출력 레이어\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "input_dim = X.shape[1]\n",
    "model = TransformerModel(input_dim=input_dim, embed_dim=64, num_heads=4, num_layers=2, hidden_dim=128, output_dim=1)\n",
    "model = TransformerModel(input_dim=input_dim, embed_dim=16, num_heads=1, num_layers=2, hidden_dim=32, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 모델 학습 ---\n",
    "model.to(device)\n",
    "\n",
    "criterion = RMLSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 루프\n",
    "def train_model(model: torch.nn.Module, \n",
    "    train_loader: torch.utils.data.DataLoader, \n",
    "    val_loader: torch.utils.data.DataLoader, \n",
    "    criterion: torch.nn.Module, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    epochs=10\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # 검증 루프\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        torch.save(model.state_dict(), model_path+f\"model_{epoch:04d}_embed_dim={model.embed_dim}_num_heads={model.num_heads}_num_layers={model.num_layers}_hidden_dim={model.hidden_dim}_dropout={model.dropout}.pt\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.0680, Val Loss: 1.0628\n",
      "Epoch 2/10, Train Loss: 1.0608, Val Loss: 1.0577\n",
      "Epoch 3/10, Train Loss: 1.0592, Val Loss: 1.0576\n",
      "Epoch 4/10, Train Loss: 1.0584, Val Loss: 1.0589\n",
      "Epoch 5/10, Train Loss: 1.0576, Val Loss: 1.0560\n",
      "Epoch 6/10, Train Loss: 1.0548, Val Loss: 1.0505\n",
      "Epoch 7/10, Train Loss: 1.0531, Val Loss: 1.0492\n",
      "Epoch 8/10, Train Loss: 1.0516, Val Loss: 1.0483\n",
      "Epoch 9/10, Train Loss: 1.0513, Val Loss: 1.0478\n",
      "Epoch 10/10, Train Loss: 1.0501, Val Loss: 1.0479\n"
     ]
    }
   ],
   "source": [
    "# target val loss is under 0.9124044109944525\n",
    "# with dropout, layer normalization, lgb feature splited into folds\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.9210, Val Loss: 0.9170\n",
      "Epoch 2/10, Train Loss: 0.9148, Val Loss: 0.9145\n",
      "Epoch 3/10, Train Loss: 0.9137, Val Loss: 0.9146\n",
      "Epoch 4/10, Train Loss: 0.9133, Val Loss: 0.9140\n",
      "Epoch 5/10, Train Loss: 0.9129, Val Loss: 0.9135\n",
      "Epoch 6/10, Train Loss: 0.9127, Val Loss: 0.9134\n",
      "Epoch 7/10, Train Loss: 0.9125, Val Loss: 0.9140\n",
      "Epoch 8/10, Train Loss: 0.9124, Val Loss: 0.9137\n",
      "Epoch 9/10, Train Loss: 0.9122, Val Loss: 0.9135\n",
      "Epoch 10/10, Train Loss: 0.9121, Val Loss: 0.9135\n"
     ]
    }
   ],
   "source": [
    "# target val loss is under 0.9124044109944525\n",
    "# criterion is mse\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predict = []\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch).detach().cpu().numpy()\n",
    "        predict.append(outputs)\n",
    "        \n",
    "outputs = np.concatenate(predict).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "y_pred = inverse_y(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([846.1098 , 839.7717 , 803.478  , ..., 834.14777, 842.8161 ,\n",
       "       772.63684], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended=pd.read_csv('./blended_best_submission.csv', index_col=0)['Premium Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([898.5813348 , 902.25194017, 836.39802692, ..., 875.01483421,\n",
       "       841.06585426, 817.94934738])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24433078558692922"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_log_error as rmsle\n",
    "rmsle(y_pred, blended.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
